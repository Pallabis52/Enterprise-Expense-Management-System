spring.application.name=Expense Management

# Database Configuration
# Database Configuration
spring.datasource.url=jdbc:postgresql://localhost:5432/expense_management
spring.datasource.username=postgres
spring.datasource.password=Aditya
spring.datasource.driver-class-name=org.postgresql.Driver
spring.jpa.hibernate.ddl-auto=update
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.format_sql=true


# File upload configuration
app.file.upload-dir=uploads
spring.servlet.multipart.max-file-size=10MB
spring.servlet.multipart.max-request-size=20MB

server.port=8081

# ── Ollama AI (Standardized on Phi-3) ─────────────────────────────────────────
ollama.base-url=http://127.0.0.1:11434
# phi3 is the standardized model for all tasks
ollama.model=phi3
# Lightweight model for simple tasks (categorize, policy check)
ollama.light-model=phi3
# phi3 is generally faster but keeping 90s timeout for safety on CPU
ollama.timeout-seconds=90
# TCP connect timeout in seconds (fast-fail when Ollama is completely down)
ollama.connect-timeout-seconds=8
# Retry config: 2 retries with 3s back-off for transient Netty failures
ollama.retry.max-attempts=2
ollama.retry.backoff-seconds=3
# Send a warm-up prompt at startup so the model is already loaded
# Disable warm-up to save startup RAM on 6GB system
ollama.warmup.enabled=false

# ── AI Response Cache (Caffeine) ─────────────────────────────────────────────
# 5-minute TTL, max 200 cached entries — no Redis needed
spring.cache.type=caffeine
spring.cache.caffeine.spec=maximumSize=200,expireAfterWrite=5m

# ── DevTools — allow restart for AI package to avoid classloader mismatch ───
ollama.async.enabled=true

# ── Security Debugging ─────────────────────────────────────────────────────────
logging.level.com.expensemanagement.Security=DEBUG
logging.level.org.springframework.security=DEBUG
logging.level.org.springframework.security.web.access=DEBUG
